From ae25a3f3ac9445a0a368027e450b1e80730f5a2a Mon Sep 17 00:00:00 2001
From: SeongJae Park <sjpark@amazon.de>
Date: Tue, 23 Nov 2021 14:01:59 +0000
Subject: Revert "mm/damon: Introduce arbitrary target type"

This reverts commit d8561a6db7bf989814b8b95e7c2c78535ac39696.
---
 include/linux/damon.h | 42 +++++++---------------------------------
 mm/damon/core.c       | 45 +++++++++++++++----------------------------
 mm/damon/dbgfs.c      |  2 +-
 3 files changed, 24 insertions(+), 65 deletions(-)

diff --git a/include/linux/damon.h b/include/linux/damon.h
index bb97b0d2f874..715dadd21f7c 100644
--- a/include/linux/damon.h
+++ b/include/linux/damon.h
@@ -144,8 +144,7 @@ struct damon_ctx;
  *
  * @init should initialize primitive-internal data structures.  For example,
  * this could be used to construct proper monitoring target regions and link
- * those to @damon_ctx.target if @damon_ctx.target_type is
- * &DAMON_ARBITRARY_TARGET.  Otherwise, &struct damon_region should be used.
+ * those to @damon_ctx.adaptive_targets.
  * @update should update the primitive-internal data structures.  For example,
  * this could be used to update monitoring target regions for current status.
  * @prepare_access_checks should manipulate the monitoring regions to be
@@ -160,8 +159,7 @@ struct damon_ctx;
  * DAMON-based operation scheme is found.  It should apply the scheme's action
  * to the region.  This is not used for &DAMON_ARBITRARY_TARGET case.
  * @target_valid should check whether the target is still valid for the
- * monitoring.  It receives &damon_ctx.arbitrary_target or &struct damon_target
- * pointer depends on &damon_ctx.target_type.
+ * monitoring.
  * @cleanup is called from @kdamond just before its termination.
  */
 struct damon_primitive {
@@ -207,17 +205,6 @@ struct damon_callback {
 	int (*before_terminate)(struct damon_ctx *context);
 };
 
-/**
- * enum damon_target_type - Represents the type of the monitoring target.
- *
- * @DAMON_ADAPTIVE_TARGET:	Adaptive regions adjustment applied target.
- * @DAMON_ARBITRARY_TARGET:	User-defined arbitrary type target.
- */
-enum damon_target_type {
-	DAMON_ADAPTIVE_TARGET,
-	DAMON_ARBITRARY_TARGET,
-};
-
 /**
  * struct damon_ctx - Represents a context for each monitoring.  This is the
  * main interface that allows users to set the attributes and get the results
@@ -258,18 +245,10 @@ enum damon_target_type {
  * @primitive:	Set of monitoring primitives for given use cases.
  * @callback:	Set of callbacks for monitoring events notifications.
  *
- * @target_type:	Type of the monitoring target.
- *
  * @min_nr_regions:	The minimum number of adaptive monitoring regions.
  * @max_nr_regions:	The maximum number of adaptive monitoring regions.
  * @adaptive_targets:	Head of monitoring targets (&damon_target) list.
  * @schemes:		Head of schemes (&damos) list.
- *
- * @arbitrary_target:	Pointer to arbitrary type target.
- *
- * @min_nr_regions, @max_nr_regions, @adaptive_targets and @schemes are valid
- * only if @target_type is &DAMON_ADAPTIVE_TARGET.  @arbitrary_target is valid
- * only if @target_type is &DAMON_ARBITRARY_TARGET.
  */
 struct damon_ctx {
 	unsigned long sample_interval;
@@ -288,17 +267,10 @@ struct damon_ctx {
 	struct damon_primitive primitive;
 	struct damon_callback callback;
 
-	enum damon_target_type target_type;
-	union {
-		struct {		/* DAMON_ADAPTIVE_TARGET */
-			unsigned long min_nr_regions;
-			unsigned long max_nr_regions;
-			struct list_head adaptive_targets;
-			struct list_head schemes;
-		};
-
-		void *arbitrary_target;	/* DAMON_ARBITRARY_TARGET */
-	};
+	unsigned long min_nr_regions;
+	unsigned long max_nr_regions;
+	struct list_head adaptive_targets;
+	struct list_head schemes;
 };
 
 #define damon_next_region(r) \
@@ -348,7 +320,7 @@ void damon_free_target(struct damon_target *t);
 void damon_destroy_target(struct damon_target *t);
 unsigned int damon_nr_regions(struct damon_target *t);
 
-struct damon_ctx *damon_new_ctx(enum damon_target_type type);
+struct damon_ctx *damon_new_ctx(void);
 void damon_destroy_ctx(struct damon_ctx *ctx);
 int damon_set_targets(struct damon_ctx *ctx,
 		unsigned long *ids, ssize_t nr_ids);
diff --git a/mm/damon/core.c b/mm/damon/core.c
index af74d63302c5..cb0b0db6bbab 100644
--- a/mm/damon/core.c
+++ b/mm/damon/core.c
@@ -176,7 +176,7 @@ unsigned int damon_nr_regions(struct damon_target *t)
 	return t->nr_regions;
 }
 
-struct damon_ctx *damon_new_ctx(enum damon_target_type type)
+struct damon_ctx *damon_new_ctx(void)
 {
 	struct damon_ctx *ctx;
 
@@ -193,14 +193,11 @@ struct damon_ctx *damon_new_ctx(enum damon_target_type type)
 
 	mutex_init(&ctx->kdamond_lock);
 
-	ctx->target_type = type;
-	if (type != DAMON_ARBITRARY_TARGET) {
-		ctx->min_nr_regions = 10;
-		ctx->max_nr_regions = 1000;
+	ctx->min_nr_regions = 10;
+	ctx->max_nr_regions = 1000;
 
-		INIT_LIST_HEAD(&ctx->adaptive_targets);
-		INIT_LIST_HEAD(&ctx->schemes);
-	}
+	INIT_LIST_HEAD(&ctx->adaptive_targets);
+	INIT_LIST_HEAD(&ctx->schemes);
 
 	return ctx;
 }
@@ -295,10 +292,8 @@ int damon_set_attrs(struct damon_ctx *ctx, unsigned long sample_int,
 	ctx->sample_interval = sample_int;
 	ctx->aggr_interval = aggr_int;
 	ctx->primitive_update_interval = primitive_upd_int;
-	if (ctx->target_type != DAMON_ARBITRARY_TARGET) {
-		ctx->min_nr_regions = min_nr_reg;
-		ctx->max_nr_regions = max_nr_reg;
-	}
+	ctx->min_nr_regions = min_nr_reg;
+	ctx->max_nr_regions = max_nr_reg;
 
 	return 0;
 }
@@ -752,9 +747,6 @@ static bool kdamond_need_stop(struct damon_ctx *ctx)
 	if (!ctx->primitive.target_valid)
 		return false;
 
-	if (ctx->target_type == DAMON_ARBITRARY_TARGET)
-		return !ctx->primitive.target_valid(ctx->arbitrary_target);
-
 	damon_for_each_target(t, ctx) {
 		if (ctx->primitive.target_valid(t))
 			return false;
@@ -803,18 +795,15 @@ static int kdamond_fn(void *data)
 			max_nr_accesses = ctx->primitive.check_accesses(ctx);
 
 		if (kdamond_aggregate_interval_passed(ctx)) {
-			if (ctx->target_type != DAMON_ARBITRARY_TARGET)
-				kdamond_merge_regions(ctx,
-						max_nr_accesses / 10,
-						sz_limit);
+			kdamond_merge_regions(ctx,
+					max_nr_accesses / 10,
+					sz_limit);
 			if (ctx->callback.after_aggregation &&
 					ctx->callback.after_aggregation(ctx))
 				set_kdamond_stop(ctx);
-			if (ctx->target_type != DAMON_ARBITRARY_TARGET) {
-				kdamond_apply_schemes(ctx);
-				kdamond_reset_aggregated(ctx);
-				kdamond_split_regions(ctx);
-			}
+			kdamond_apply_schemes(ctx);
+			kdamond_reset_aggregated(ctx);
+			kdamond_split_regions(ctx);
 			if (ctx->primitive.reset_aggregated)
 				ctx->primitive.reset_aggregated(ctx);
 		}
@@ -825,11 +814,9 @@ static int kdamond_fn(void *data)
 			sz_limit = damon_region_sz_limit(ctx);
 		}
 	}
-	if (ctx->target_type != DAMON_ARBITRARY_TARGET) {
-		damon_for_each_target(t, ctx) {
-			damon_for_each_region_safe(r, next, t)
-				damon_destroy_region(r, t);
-		}
+	damon_for_each_target(t, ctx) {
+		damon_for_each_region_safe(r, next, t)
+			damon_destroy_region(r, t);
 	}
 
 	if (ctx->callback.before_terminate &&
diff --git a/mm/damon/dbgfs.c b/mm/damon/dbgfs.c
index ae3370bf248b..e5d24c5185c4 100644
--- a/mm/damon/dbgfs.c
+++ b/mm/damon/dbgfs.c
@@ -898,7 +898,7 @@ static struct damon_ctx *dbgfs_new_ctx(void)
 {
 	struct damon_ctx *ctx;
 
-	ctx = damon_new_ctx(DAMON_ADAPTIVE_TARGET);
+	ctx = damon_new_ctx();
 	if (!ctx)
 		return NULL;
 
-- 
2.32.0

